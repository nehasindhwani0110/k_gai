# Complete System Flow - End-to-End Explanation

## ğŸ¯ Overview

This document explains the **complete flow** of the analytics engine from file upload to visualization, covering all components and their interactions.

---

## ğŸ“Š **FLOW 1: File Upload & Schema Detection**

### Step-by-Step Flow:

```
1. User uploads file (CSV/JSON/Excel/Text)
   â†“
2. Frontend: FileUpload.tsx
   - Validates file type (.csv, .json, .xlsx, .xls, .txt)
   - Validates file size (< 10MB)
   - Shows upload progress
   â†“
3. POST /api/analytics/upload
   - Saves file to /uploads directory
   - Generates unique filename: timestamp_filename.ext
   - Returns: { file_path, file_name, file_size, file_type }
   â†“
4. Frontend calls POST /api/analytics/schema
   - Sends: { source_type: 'CSV_FILE', file_path, file_type }
   â†“
5. Backend: processFile() in file-processor.ts
   - Reads file content
   - Detects file type (CSV/JSON/Excel/Text)
   - Parses first few rows
   - Infers column types (INT, DECIMAL, TEXT, DATE, BOOLEAN)
   - Creates TableMetadata structure
   â†“
6. Backend saves to FileMetadata table (Prisma)
   - Stores: fileName, filePath, fileType, fileSize, metadata (JSON)
   â†“
7. Returns DataSourceMetadata:
   {
     source_type: 'CSV_FILE',
     tables: [{
       name: 'comprehensive_student_data_5k',
       columns: [
         { name: 'cgpa', type: 'DECIMAL' },
         { name: 'full_name', type: 'TEXT' },
         ...
       ]
     }],
     file_path: '/uploads/1234567890_file.csv'
   }
   â†“
8. Frontend updates metadata state
   - DashboardMetrics and AdhocQuery components receive metadata
   - Ready for queries!
```

**Key Files:**
- `components/analytics/FileUpload.tsx`
- `app/api/analytics/upload/route.ts`
- `app/api/analytics/schema/route.ts`
- `analytics-engine/services/file-processor.ts`
- `analytics-engine/services/query-history-service.ts` (saves FileMetadata)

---

## ğŸ“Š **FLOW 2: Dashboard Metrics Generation**

### Step-by-Step Flow:

```
1. User navigates to Dashboard Metrics tab
   â†“
2. Frontend: DashboardMetrics.tsx
   - useEffect triggers loadDashboardMetrics()
   - Shows loading spinner
   â†“
3. POST /api/analytics
   Body: {
     mode: 'DASHBOARD_METRICS',
     metadata: { source_type, tables, file_path, ... }
   }
   â†“
4. Backend: llm-service.ts â†’ generateDashboardMetrics()
   - Constructs MASTER_PROMPT_TEMPLATE with metadata
   - Sends to OpenAI GPT-4
   - Prompt instructs AI to:
     * Analyze metadata to understand data domain
     * Generate 6-8 key metrics covering ALL chart types
     * Use actual column names from metadata
     * Create queries that return multiple rows for visualization
   â†“
5. OpenAI returns JSON:
   {
     dashboard_metrics: [
       {
         metric_name: "Average CGPA by Academic Stream",
         query_type: "SQL_QUERY",
         query_content: "SELECT academic_stream, AVG(cgpa) as avg_cgpa FROM comprehensive_student_data_5k GROUP BY academic_stream ORDER BY avg_cgpa DESC",
         visualization_type: "auto",
         insight_summary: "..."
       },
       // ... 5-7 more metrics
     ]
   }
   â†“
6. Backend: query-post-processor.ts
   - Post-processes queries to ensure correct table names
   - Fixes any table name mismatches
   â†“
7. Returns dashboard_metrics array to frontend
   â†“
8. Frontend: DashboardMetrics.tsx
   - Sets metrics state
   - For each metric, calls executeMetricQuery()
   â†“
9. For each metric:
   POST /api/analytics/execute
   Body: {
     query_type: 'SQL_QUERY',
     query_content: 'SELECT ...',
     source_type: 'CSV_FILE',
     file_path: '/uploads/...',
     file_type: 'CSV'
   }
   â†“
10. Backend: csv-query-executor.ts â†’ executeCSVQuery()
    - Reads CSV file
    - Parses SQL query (SELECT, FROM, WHERE, GROUP BY, ORDER BY, LIMIT)
    - Applies WHERE filters
    - Groups records (if GROUP BY)
    - Calculates aggregates (COUNT, SUM, AVG, MAX, MIN)
    - Sorts results (ORDER BY)
    - Limits results (LIMIT)
    - Returns array of objects
    â†“
11. Frontend receives results
    - Stores in metricResults state: { [metric_name]: results[] }
    â†“
12. Frontend: VisualizationRenderer
    - Calls autoSelectVisualizationType() to choose chart type
    - Renders appropriate chart component (BarChart, LineChart, PieChart, etc.)
    â†“
13. User sees 6-8 beautiful visualizations!
```

**Key Files:**
- `components/analytics/DashboardMetrics.tsx`
- `app/api/analytics/route.ts`
- `analytics-engine/services/llm-service.ts`
- `analytics-engine/services/query-post-processor.ts`
- `app/api/analytics/execute/route.ts`
- `analytics-engine/services/csv-query-executor.ts`
- `analytics-engine/services/visualization-selector.ts`
- `components/analytics/VisualizationRenderer.tsx`

---

## ğŸ“Š **FLOW 3: Ad-Hoc Query (Natural Language â†’ SQL â†’ Results)**

### Step-by-Step Flow:

```
1. User types question: "What is the average CGPA by academic stream?"
   â†“
2. Frontend: AdhocQuery.tsx
   - User clicks "Ask" button
   - Shows loading state
   â†“
3. POST /api/analytics
   Body: {
     mode: 'ADHOC_QUERY',
     metadata: { source_type, tables, file_path, ... },
     user_question: "What is the average CGPA by academic stream?"
   }
   â†“
4. Backend: llm-service.ts â†’ generateAdhocQuery()
   - Constructs MASTER_PROMPT_TEMPLATE with:
     * User question
     * Data source metadata (tables, columns, types)
     * Instructions to generate EXACT SQL query
   - Sends to OpenAI GPT-4
   â†“
5. OpenAI analyzes question and metadata:
   - Understands: "average CGPA" â†’ AVG(cgpa)
   - Understands: "by academic stream" â†’ GROUP BY academic_stream
   - Uses exact column names from metadata
   â†“
6. OpenAI returns JSON:
   {
     query_type: "SQL_QUERY",
     query_content: "SELECT academic_stream, AVG(cgpa) as avg_cgpa FROM comprehensive_student_data_5k GROUP BY academic_stream ORDER BY avg_cgpa DESC",
     visualization_type: "auto",
     insight_summary: "Average CGPA varies across academic streams..."
   }
   â†“
7. Frontend receives result
   - Displays generated SQL query
   - Displays insight summary
   - Automatically calls executeQuery()
   â†“
8. POST /api/analytics/execute
   Body: {
     query_type: 'SQL_QUERY',
     query_content: 'SELECT academic_stream, AVG(cgpa)...',
     source_type: 'CSV_FILE',
     file_path: '/uploads/...',
     file_type: 'CSV'
   }
   â†“
9. Backend: csv-query-executor.ts â†’ executeCSVQuery()
   - Parses SQL query
   - Reads CSV file
   - Applies GROUP BY academic_stream
   - Calculates AVG(cgpa) per group
   - Orders by avg_cgpa DESC
   - Returns: [
       { academic_stream: 'Science', avg_cgpa: 8.5 },
       { academic_stream: 'Commerce', avg_cgpa: 7.8 },
       ...
     ]
   â†“
10. Frontend receives results
    - Stores in queryResults state
    â†“
11. Frontend: VisualizationRenderer
    - Calls autoSelectVisualizationType()
    - Analyzes: multiple rows, GROUP BY, numeric values
    - Selects: 'bar_chart' (best for comparisons)
    - Renders BarChart component
    â†“
12. User sees beautiful bar chart!
    â†“
13. Frontend automatically saves to QueryHistory
    POST /api/analytics/history
    Body: {
      userQuestion: "What is the average CGPA by academic stream?",
      queryType: "SQL_QUERY",
      queryContent: "SELECT ...",
      sourceType: "CSV_FILE",
      filePath: "/uploads/...",
      results: [...]
    }
    â†“
14. Saved to database (QueryHistory table)
```

**Key Files:**
- `components/analytics/AdhocQuery.tsx`
- `app/api/analytics/route.ts`
- `analytics-engine/services/llm-service.ts`
- `app/api/analytics/execute/route.ts`
- `analytics-engine/services/csv-query-executor.ts`
- `analytics-engine/services/visualization-selector.ts`
- `components/analytics/VisualizationRenderer.tsx`
- `app/api/analytics/history/route.ts`

---

## ğŸ“Š **FLOW 4: Query History**

### Step-by-Step Flow:

```
1. User opens Query History section
   â†“
2. Frontend: QueryHistory.tsx
   - Calls GET /api/analytics/history?limit=50
   â†“
3. Backend: query-history-service.ts â†’ getQueryHistory()
   - Queries Prisma: QueryHistory table
   - Orders by createdAt DESC
   - Returns last 50 queries
   â†“
4. Frontend displays list:
   - Question asked
   - SQL query generated
   - Timestamp
   - Source type
   - Click to reuse
   â†“
5. User clicks a query
   - Question populated in input field
   - User can modify and re-execute
   â†“
6. User clicks delete (âœ•)
   - DELETE /api/analytics/history?id=<id>
   - Removes from database
   - UI updates
```

**Key Files:**
- `components/analytics/QueryHistory.tsx`
- `app/api/analytics/history/route.ts`
- `analytics-engine/services/query-history-service.ts`
- `prisma/schema.prisma` (QueryHistory model)

---

## ğŸ“Š **FLOW 5: Multi-Tenant SQL Database (Canonical Mapping)**

### Step-by-Step Flow:

```
1. Admin registers School A database
   POST /api/analytics/data-sources
   Body: {
     name: "School A",
     sourceType: "SQL_DB",
     connectionString: "postgresql://...",
     autoRegisterSchema: true
   }
   â†“
2. Backend: canonical-mapping-service.ts â†’ registerDataSource()
   - Creates DataSource record in database
   - Returns dataSourceId: "clx123..."
   â†“
3. Backend: introspectSQLSchema() (via SQLAlchemy)
   - Connects to PostgreSQL database
   - Queries information_schema
   - Discovers tables: tbl_students, tbl_grades, etc.
   - Discovers columns: stu_id, stu_name, cgpa, etc.
   â†“
4. Backend: autoRegisterSchemaFromIntrospection()
   - Normalizes names:
     * tbl_students â†’ students
     * stu_id â†’ student_id
     * stu_name â†’ student_name
   - Creates SchemaMapping records:
     * sourceTable: "tbl_students" â†’ canonicalTable: "students"
     * sourceColumn: "stu_id" â†’ canonicalColumn: "student_id"
   - Creates SchemaRegistry records
   â†“
5. User asks: "Show top 10 students by CGPA"
   â†“
6. Frontend: GET /api/analytics/data-sources/clx123.../schema
   - Returns canonical schema:
     {
       source_type: "CANONICAL_DB",
       tables: [{
         name: "students",
         columns: [
           { name: "student_id", type: "INTEGER" },
           { name: "student_name", type: "VARCHAR" },
           { name: "cgpa", type: "DECIMAL" }
         ]
       }]
     }
   â†“
7. POST /api/analytics (mode: ADHOC_QUERY)
   - LLM sees canonical schema
   - Generates canonical query:
     "SELECT student_name, cgpa FROM students ORDER BY cgpa DESC LIMIT 10"
   â†“
8. POST /api/analytics/execute
   Body: {
     query_type: "SQL_QUERY",
     query_content: "SELECT student_name, cgpa FROM students...",
     source_type: "SQL_DB",
     connection_string: "postgresql://...",
     data_source_id: "clx123...",
     is_canonical_query: true
   }
   â†“
9. Backend: translateCanonicalQuery()
   - Looks up mappings for dataSourceId
   - Replaces: students â†’ tbl_students
   - Replaces: student_name â†’ stu_name
   - Returns: "SELECT stu_name, cgpa FROM tbl_students ORDER BY cgpa DESC LIMIT 10"
   â†“
10. Backend: executeSQLQuery()
    - Executes translated query on School A database
    - Returns results
    â†“
11. Frontend displays results!
```

**Key Files:**
- `app/api/analytics/data-sources/route.ts`
- `analytics-engine/services/canonical-mapping-service.ts`
- `analytics-engine/services/schema-introspection.ts`
- `app/api/analytics/data-sources/[id]/translate/route.ts`
- `prisma/schema.prisma` (DataSource, SchemaRegistry, SchemaMapping models)

---

## ğŸ“Š **FLOW 6: Auto-Refresh Dashboard**

### Step-by-Step Flow:

```
1. User opens Dashboard Metrics tab
   â†“
2. Frontend: DashboardMetrics.tsx
   - Loads metrics immediately
   - Sets up useEffect with setInterval
   â†“
3. Every hour (3600000ms):
   - Automatically calls loadDashboardMetrics()
   - Refreshes all metrics
   - Updates lastRefresh timestamp
   - Shows countdown timer
   â†“
4. User can also:
   - Click "ğŸ”„ Refresh Now" for manual refresh
   - Toggle "Auto-refresh ON/OFF"
   â†“
5. Timer shows: "Next refresh in: 45m 30s"
```

**Key Files:**
- `components/analytics/DashboardMetrics.tsx`
- `app/api/analytics/refresh/route.ts`

---

## ğŸ“Š **FLOW 7: AI Suggestions**

### Step-by-Step Flow:

```
1. User opens Adhoc Query tab
   â†“
2. Frontend: AIAnalyticsSuggestions.tsx
   - Expands suggestions panel
   - Calls POST /api/analytics/suggestions
   â†“
3. Backend: ai-analytics-suggestions.ts â†’ generateAISuggestions()
   - Sends metadata to OpenAI
   - Asks AI to generate 10-15 relevant questions
   - Categorizes by priority (High/Medium/Low)
   â†“
4. OpenAI returns:
   [
     {
       question: "What is the average CGPA by academic stream?",
       category: "Performance",
       priority: "High"
     },
     ...
   ]
   â†“
5. Frontend displays suggestions
   - Color-coded by priority
   - Clickable to populate question field
   â†“
6. User clicks suggestion
   - Question auto-filled
   - Can modify and submit
```

**Key Files:**
- `components/analytics/AIAnalyticsSuggestions.tsx`
- `app/api/analytics/suggestions/route.ts`
- `analytics-engine/services/ai-analytics-suggestions.ts`

---

## ğŸ”„ **Complete End-to-End Flow Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ File Upload  â”‚  â”‚  Dashboard    â”‚  â”‚  Adhoc Query â”‚        â”‚
â”‚  â”‚   Component  â”‚  â”‚   Metrics     â”‚  â”‚   Component   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API ROUTES (Next.js)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ /upload      â”‚  â”‚ /analytics   â”‚  â”‚ /execute     â”‚        â”‚
â”‚  â”‚ /schema      â”‚  â”‚ /suggestions  â”‚  â”‚ /history     â”‚        â”‚
â”‚  â”‚ /refresh     â”‚  â”‚ /data-sourcesâ”‚  â”‚              â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ANALYTICS ENGINE SERVICES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  File Processor (CSV/JSON/Excel/Text)                 â”‚     â”‚
â”‚  â”‚  - Reads file, infers schema, creates metadata        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  LLM Service (OpenAI GPT-4)                          â”‚     â”‚
â”‚  â”‚  - Generates SQL queries from natural language       â”‚     â”‚
â”‚  â”‚  - Generates dashboard metrics                       â”‚     â”‚
â”‚  â”‚  - Generates AI suggestions                          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Query Executor                                       â”‚     â”‚
â”‚  â”‚  - CSV Query Executor (in-memory SQL parser)          â”‚     â”‚
â”‚  â”‚  - File Query Executor (JSON/Excel/Text)             â”‚     â”‚
â”‚  â”‚  - SQL Query Executor (for databases)                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Canonical Mapping Service                            â”‚     â”‚
â”‚  â”‚  - Registers data sources                            â”‚     â”‚
â”‚  â”‚  - Maps schemas (source â†’ canonical)                 â”‚     â”‚
â”‚  â”‚  - Translates queries (canonical â†’ source)          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Visualization Selector                              â”‚     â”‚
â”‚  â”‚  - Analyzes query results                            â”‚     â”‚
â”‚  â”‚  - Auto-selects best chart type                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Query History Service                               â”‚     â”‚
â”‚  â”‚  - Saves queries to database                        â”‚     â”‚
â”‚  â”‚  - Retrieves query history                          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA STORAGE                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ File System  â”‚  â”‚  Database    â”‚  â”‚  Database    â”‚        â”‚
â”‚  â”‚  /uploads/   â”‚  â”‚ (SQLite)     â”‚  â”‚ (SQLite)     â”‚        â”‚
â”‚  â”‚              â”‚  â”‚ QueryHistory â”‚  â”‚ System Tablesâ”‚        â”‚
â”‚  â”‚              â”‚  â”‚ FileMetadata â”‚  â”‚ DataSource   â”‚        â”‚
â”‚  â”‚              â”‚  â”‚ Dashboard    â”‚  â”‚ SchemaReg    â”‚        â”‚
â”‚  â”‚              â”‚  â”‚ Metric        â”‚  â”‚ SchemaMap    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ **Key Components Summary**

### **Frontend Components:**
1. **FileUpload.tsx** - Handles file uploads
2. **DashboardMetrics.tsx** - Displays auto-generated metrics
3. **AdhocQuery.tsx** - Natural language query interface
4. **QueryHistory.tsx** - Shows past queries
5. **AIAnalyticsSuggestions.tsx** - AI-generated question suggestions
6. **VisualizationRenderer.tsx** - Renders charts (Bar, Line, Pie, etc.)

### **Backend Services:**
1. **file-processor.ts** - Processes CSV/JSON/Excel/Text files
2. **llm-service.ts** - OpenAI integration for query generation
3. **csv-query-executor.ts** - Executes SQL-like queries on CSV files
4. **file-query-executor.ts** - Executes queries on JSON/Excel/Text files
5. **canonical-mapping-service.ts** - Multi-tenant schema mapping
6. **query-history-service.ts** - Query history management
7. **visualization-selector.ts** - Auto-selects chart types
8. **query-post-processor.ts** - Post-processes generated queries

### **API Endpoints:**
1. `/api/analytics/upload` - File upload
2. `/api/analytics/schema` - Schema introspection
3. `/api/analytics` - Generate queries/metrics
4. `/api/analytics/execute` - Execute queries
5. `/api/analytics/suggestions` - AI suggestions
6. `/api/analytics/history` - Query history
7. `/api/analytics/refresh` - Refresh dashboard
8. `/api/analytics/data-sources` - Manage data sources
9. `/api/analytics/data-sources/[id]/schema` - Manage schemas
10. `/api/analytics/data-sources/[id]/translate` - Translate queries

### **Database Tables (Prisma):**
1. **QueryHistory** - Stores past queries
2. **FileMetadata** - Tracks uploaded files
3. **DashboardMetric** - Caches dashboard metrics
4. **DataSource** - Stores SQL database connections
5. **SchemaRegistry** - Maps source â†’ canonical schemas
6. **SchemaMapping** - Stores transformation rules

---

## ğŸ”„ **Data Flow Summary**

### **File-Based Analytics:**
```
File Upload â†’ Schema Detection â†’ Metadata Creation â†’ 
Query Generation (LLM) â†’ Query Execution (CSV Parser) â†’ 
Results â†’ Visualization â†’ History Save
```

### **SQL Database Analytics (Multi-tenant):**
```
Register Database â†’ Schema Introspection â†’ Canonical Mapping â†’ 
Query Generation (LLM with Canonical Schema) â†’ 
Query Translation (Canonical â†’ Source) â†’ 
Query Execution (SQLAlchemy) â†’ Results â†’ Visualization
```

---

## ğŸ’¡ **Key Features**

1. **Domain-Agnostic**: Works with ANY data (education, business, healthcare, etc.)
2. **Multi-Format Support**: CSV, JSON, Excel, Text files
3. **Multi-Tenant SQL**: Canonical mapping for multiple databases
4. **AI-Powered**: GPT-4 generates queries and suggestions
5. **Auto-Visualization**: Automatically selects best chart type
6. **Query History**: Saves and reuses past queries
7. **Auto-Refresh**: Dashboard refreshes every hour
8. **Beautiful UI**: Modern, colorful visualizations

---

## ğŸ¯ **Complete Example: User Journey**

### **Scenario**: User wants to analyze student data

1. **Upload File**
   - User drags `students.csv` to upload area
   - System detects: 5000 rows, columns: cgpa, full_name, academic_stream, etc.
   - Metadata created and saved

2. **View Dashboard**
   - System generates 6-8 metrics automatically
   - Shows: Average CGPA, CGPA by Stream, Placement Status, etc.
   - Beautiful charts displayed

3. **Ask Question**
   - User types: "Which state has the most students?"
   - AI generates: `SELECT state, COUNT(*) as count FROM students GROUP BY state ORDER BY count DESC LIMIT 1`
   - Query executes on CSV file
   - Bar chart shows results
   - Query saved to history

4. **Reuse Query**
   - User opens Query History
   - Clicks previous query
   - Question populated, can modify and re-run

5. **Connect SQL Database** (if needed)
   - Admin registers School A database
   - System auto-maps schema
   - User can now query using canonical names
   - Queries automatically translate to School A's schema

---

This is the **complete flow** of your analytics engine! ğŸš€

