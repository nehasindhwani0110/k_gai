# K-GAI Analytics Engine - Complete System Flow & Documentation

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Technology Stack](#technology-stack)
3. [Architecture](#architecture)
4. [Complete System Flow](#complete-system-flow)
5. [Key Components](#key-components)
6. [API Endpoints](#api-endpoints)
7. [File Structure](#file-structure)
8. [Setup & Installation](#setup--installation)

---

## ğŸ¯ Overview

**K-GAI Analytics Engine** is a multi-tenant, AI-powered analytics platform that converts natural language questions into SQL queries and generates beautiful visualizations. It supports both SQL databases and CSV files, with intelligent schema detection, query generation, and automatic visualization selection.

### Key Features

- ğŸ” **Multi-tenant authentication** (School-based login)
- ğŸ¤– **AI-powered query generation** (OpenAI GPT-4)
- ğŸ“Š **Automatic visualization** (Bar, Line, Pie, Scatter, Gauge, Table)
- ğŸ” **Schema introspection** (Automatic table/column detection)
- ğŸ“ **CSV file support** (Upload and query CSV files)
- ğŸ—„ï¸ **SQL database support** (MySQL, PostgreSQL, SQLite)
- ğŸ”„ **Agent-based query generation** (LangChain/LangGraph)
- ğŸ“ˆ **Dashboard metrics** (Auto-generated analytics)
- ğŸ”§ **Query auto-fixing** (Handles GROUP BY errors, column errors)
- ğŸ“ **Query history** (Track all queries)
- ğŸ¨ **PowerBI-style visualizations**

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **Framework**: Next.js 14 (React 18)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Charts**: Recharts
- **State Management**: React Hooks
- **Notifications**: react-hot-toast
- **File Parsing**: papaparse, xlsx, csv-parse

### Backend (TypeScript/Node.js)
- **Runtime**: Node.js
- **Framework**: Next.js API Routes
- **Database ORM**: Prisma
- **Database**: SQLite (for metadata), MySQL/PostgreSQL (for data sources)
- **Authentication**: bcryptjs (password hashing)
- **HTTP Client**: axios

### AI/ML Stack
- **LLM Provider**: OpenAI (GPT-4 Turbo)
- **Agent Framework**: LangChain, LangGraph
- **Observability**: LangSmith (tracing, token usage, latency)
- **Packages**:
  - `openai` - OpenAI SDK
  - `@langchain/openai` - LangChain OpenAI integration
  - `@langchain/core` - Core LangChain functionality
  - `@langchain/langgraph` - LangGraph for agent workflows
  - `langsmith` - LangSmith tracing

### Backend (Python)
- **Framework**: Flask
- **Database**: SQLAlchemy
- **Agent Framework**: LangChain (Python)
- **Purpose**: Schema introspection, SQL agent execution

### Development Tools
- **TypeScript**: Type checking
- **ESLint**: Code linting
- **PostCSS**: CSS processing
- **tsx**: TypeScript execution

---

## ğŸ—ï¸ Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (Next.js)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Login      â”‚  â”‚  Analytics   â”‚  â”‚  Dashboard   â”‚      â”‚
â”‚  â”‚   Page       â”‚  â”‚    Page      â”‚  â”‚   Metrics    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Next.js API Routes                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  /api/auth   â”‚  â”‚ /api/analyticsâ”‚  â”‚ /api/execute â”‚      â”‚
â”‚  â”‚   /login     â”‚  â”‚               â”‚  â”‚              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM        â”‚  â”‚   Query      â”‚  â”‚   Python     â”‚
â”‚   Service    â”‚  â”‚   Executor   â”‚  â”‚   Backend    â”‚
â”‚              â”‚  â”‚              â”‚  â”‚   (Flask)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI     â”‚  â”‚   Database   â”‚  â”‚  LangChain   â”‚
â”‚   API        â”‚  â”‚   (SQL)      â”‚  â”‚   Agent      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

```
Frontend Components
â”œâ”€â”€ SchoolLogin.tsx          â†’ Authentication UI
â”œâ”€â”€ FileUpload.tsx           â†’ CSV upload interface
â”œâ”€â”€ AdhocQuery.tsx           â†’ Natural language query input
â”œâ”€â”€ DashboardMetrics.tsx     â†’ Auto-generated metrics display
â”œâ”€â”€ AIAnalyticsSuggestions.tsx â†’ AI-powered question suggestions
â”œâ”€â”€ QueryHistory.tsx         â†’ Query history display
â””â”€â”€ VisualizationRenderer.tsx â†’ Chart rendering
    â”œâ”€â”€ BarChart.tsx
    â”œâ”€â”€ LineChart.tsx
    â”œâ”€â”€ PieChart.tsx
    â”œâ”€â”€ ScatterPlot.tsx
    â”œâ”€â”€ Gauge.tsx
    â””â”€â”€ Table.tsx

Backend Services
â”œâ”€â”€ llm-service.ts           â†’ OpenAI query generation
â”œâ”€â”€ query-executor.ts        â†’ SQL execution & error fixing
â”œâ”€â”€ schema-introspection.ts  â†’ Database schema detection
â”œâ”€â”€ visualization-selector.ts â†’ Auto chart type selection
â”œâ”€â”€ agent-service.ts         â†’ LangChain agent integration
â””â”€â”€ langsmith-tracer.ts     â†’ LangSmith observability

Python Backend
â”œâ”€â”€ api_server.py            â†’ Flask REST API
â”œâ”€â”€ schema_introspection.py  â†’ SQLAlchemy schema detection
â”œâ”€â”€ query_executor.py        â†’ SQL query execution
â””â”€â”€ agent_service.py         â†’ LangChain SQL agent
```

---

## ğŸ”„ Complete System Flow

### Flow 1: User Login & Initial Setup

```
1. User visits http://localhost:3000
   â”‚
   â”œâ”€â–º app/page.tsx (Home page)
   â”‚   â””â”€â–º Checks sessionStorage for authentication
   â”‚       â”œâ”€â–º If authenticated â†’ Redirect to /analytics
   â”‚       â””â”€â–º If not â†’ Show SchoolLogin component
   â”‚
   â”œâ”€â–º User enters credentials (email, password)
   â”‚
   â”œâ”€â–º POST /api/auth/login
   â”‚   â”œâ”€â–º Validates credentials against Prisma DB
   â”‚   â”œâ”€â–º Checks School table (email, password hash)
   â”‚   â”œâ”€â–º Creates DataSource if doesn't exist
   â”‚   â”œâ”€â–º Links School to DataSource
   â”‚   â””â”€â–º Returns: { schoolId, dataSourceId, schoolName }
   â”‚
   â””â”€â–º Frontend stores in sessionStorage
       â””â”€â–º Redirects to /analytics page
```

### Flow 2: Schema Detection (First Time Access)

```
1. User lands on /analytics page
   â”‚
   â”œâ”€â–º app/analytics/page.tsx
   â”‚   â””â”€â–º Checks if metadata exists in DataSource
   â”‚
   â”œâ”€â–º If no metadata:
   â”‚   â”‚
   â”‚   â”œâ”€â–º GET /api/analytics/data-sources/[id]/schema
   â”‚   â”‚   â”œâ”€â–º Checks source_type (SQL_DB or CSV_FILE)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º If SQL_DB:
   â”‚   â”‚   â”‚   â”œâ”€â–º Calls Python backend: POST http://localhost:8000/introspect
   â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º schema_introspection.py
   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º SQLAlchemy connects to database
   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º Inspects all tables
   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º Gets columns, types, constraints
   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â–º Returns: { tables: [{ name, columns: [...] }] }
   â”‚   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”‚   â””â”€â–º Saves metadata to Prisma DataSource
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º If CSV_FILE:
   â”‚   â”‚       â”œâ”€â–º Reads CSV file from uploads/
   â”‚   â”‚       â”œâ”€â–º Parses headers and sample rows
   â”‚   â”‚       â”œâ”€â–º Detects data types (string, number, date)
   â”‚   â”‚       â””â”€â–º Saves metadata to Prisma DataSource
   â”‚   â”‚
   â”‚   â””â”€â–º Frontend receives metadata
   â”‚       â””â”€â–º Displays FileUpload, AdhocQuery, DashboardMetrics components
```

### Flow 3: Ad-Hoc Query Generation

```
1. User types natural language question
   Example: "What is the distribution of payment methods?"
   â”‚
   â”œâ”€â–º AdhocQuery.tsx component
   â”‚   â””â”€â–º User submits question
   â”‚
   â”œâ”€â–º POST /api/analytics
   â”‚   Body: {
   â”‚     mode: "ADHOC_QUERY",
   â”‚     user_question: "What is the distribution...",
   â”‚     metadata: { tables: [...], columns: [...] },
   â”‚     connection_string: "mysql://...",
   â”‚     use_agent: true/false
   â”‚   }
   â”‚
   â”œâ”€â–º Route handler: app/api/analytics/route.ts
   â”‚   â””â”€â–º Validates request
   â”‚
   â”œâ”€â–º Decision: Which query generation method?
   â”‚   â”‚
   â”‚   â”œâ”€â–º Option A: LangGraph Agent (if use_langgraph=true)
   â”‚   â”‚   â””â”€â–º generateAdhocQueryWithLangGraphAgent()
   â”‚   â”‚       â”œâ”€â–º QueryAgent.execute()
   â”‚   â”‚       â”‚   â”œâ”€â–º Step 1: Analyze question complexity
   â”‚   â”‚       â”‚   â”œâ”€â–º Step 2: Explore relevant schema (if needed)
   â”‚   â”‚       â”‚   â”‚   â””â”€â–º Calls schema-explorer.ts tool
   â”‚   â”‚       â”‚   â”‚       â””â”€â–º Identifies relevant tables based on question
   â”‚   â”‚       â”‚   â”œâ”€â–º Step 3: Generate query using LLM
   â”‚   â”‚       â”‚   â”‚   â””â”€â–º ChatOpenAI (LangChain) with metadata
   â”‚   â”‚       â”‚   â”œâ”€â–º Step 4: Validate query
   â”‚   â”‚       â”‚   â”‚   â””â”€â–º query-validator.ts tool
   â”‚   â”‚       â”‚   â””â”€â–º Step 5: Refine if needed
   â”‚   â”‚       â””â”€â–º Returns: SQL query string
   â”‚   â”‚
   â”‚   â”œâ”€â–º Option B: Python Agent (if use_agent=true)
   â”‚   â”‚   â””â”€â–º generateQueryWithPythonAgent()
   â”‚   â”‚       â”œâ”€â–º POST http://localhost:8000/agent/query
   â”‚   â”‚       â”‚   â””â”€â–º agent_service.py
   â”‚   â”‚       â”‚       â”œâ”€â–º Creates LangChain SQL Agent
   â”‚   â”‚       â”‚       â”œâ”€â–º Agent explores schema dynamically
   â”‚   â”‚       â”‚       â”œâ”€â–º Generates query using LLM
   â”‚   â”‚       â”‚       â””â”€â–º Returns: SQL query string
   â”‚   â”‚       â””â”€â–º Returns: SQL query
   â”‚   â”‚
   â”‚   â””â”€â–º Option C: Direct LLM (default)
   â”‚       â””â”€â–º generateAdhocQuery()
   â”‚           â”œâ”€â–º llm-service.ts
   â”‚           â”‚   â”œâ”€â–º Reduces metadata if large database (>10 tables)
   â”‚           â”‚   â”‚   â””â”€â–º Uses LLM to identify relevant tables
   â”‚           â”‚   â”œâ”€â–º Builds prompt with:
   â”‚           â”‚   â”‚   â”œâ”€â–º User question
   â”‚           â”‚   â”‚   â”œâ”€â–º Schema metadata
   â”‚           â”‚   â”‚   â””â”€â–º SQL generation rules
   â”‚           â”‚   â”œâ”€â–º Calls OpenAI API (with LangSmith tracing)
   â”‚           â”‚   â”‚   â””â”€â–º openai.chat.completions.create()
   â”‚           â”‚   â”‚       â”œâ”€â–º Model: gpt-4-turbo-preview
   â”‚           â”‚   â”‚       â”œâ”€â–º Response format: JSON
   â”‚           â”‚   â”‚       â””â”€â–º Returns: { query_content, visualization_type, insight_summary }
   â”‚           â”‚   â””â”€â–º Parses JSON response
   â”‚           â””â”€â–º Returns: AdhocQueryResponse
   â”‚
   â”œâ”€â–º Response sent to frontend
   â”‚   â””â”€â–º { query_content: "SELECT ...", visualization_type: "auto", insight_summary: "..." }
   â”‚
   â”œâ”€â–º Frontend executes query
   â”‚   â””â”€â–º POST /api/analytics/execute
   â”‚       â”œâ”€â–º query-executor.ts
   â”‚       â”‚   â”œâ”€â–º Validates SQL (security check)
   â”‚       â”‚   â”œâ”€â–º Executes query
   â”‚       â”‚   â”‚   â”œâ”€â–º If SQL_DB: Calls Python backend
   â”‚       â”‚   â”‚   â”‚   â””â”€â–º POST http://localhost:8000/execute
   â”‚       â”‚   â”‚   â”‚       â””â”€â–º query_executor.py executes SQL
   â”‚       â”‚   â”‚   â””â”€â–º If CSV_FILE: Uses csv-query-executor.ts
   â”‚       â”‚   â”‚       â””â”€â–º Parses CSV and executes query logic
   â”‚       â”‚   â”‚
   â”‚       â”‚   â”œâ”€â–º If error occurs:
   â”‚       â”‚   â”‚   â”œâ”€â–º GROUP BY error? â†’ fixGroupByWithLLM()
   â”‚       â”‚   â”‚   â”‚   â””â”€â–º Uses LLM to fix GROUP BY violations
   â”‚       â”‚   â”‚   â””â”€â–º Column error? â†’ fixColumnErrorWithLLM()
   â”‚       â”‚   â”‚       â”œâ”€â–º Introspects schema for correct columns
   â”‚       â”‚   â”‚       â””â”€â–º Uses LLM to fix column names
   â”‚       â”‚   â”‚
   â”‚       â”‚   â””â”€â–º Returns: { results: [...] }
   â”‚       â”‚
   â”‚       â””â”€â–º Frontend receives results
   â”‚
   â”œâ”€â–º Visualization Selection
   â”‚   â””â”€â–º visualization-selector.ts
   â”‚       â”œâ”€â–º Analyzes data structure
   â”‚       â”œâ”€â–º Checks query content
   â”‚       â”œâ”€â–º Considers user question
   â”‚       â””â”€â–º Selects: bar_chart, pie_chart, line_chart, etc.
   â”‚
   â””â”€â–º Render Visualization
       â””â”€â–º VisualizationRenderer.tsx
           â”œâ”€â–º BarChart.tsx (PowerBI-style)
           â”œâ”€â–º PieChart.tsx
           â”œâ”€â–º LineChart.tsx
           â””â”€â–º etc.
```

### Flow 4: Dashboard Metrics Generation

```
1. User visits /analytics page
   â”‚
   â”œâ”€â–º DashboardMetrics.tsx component loads
   â”‚
   â”œâ”€â–º POST /api/analytics
   â”‚   Body: {
   â”‚     mode: "DASHBOARD_METRICS",
   â”‚     metadata: { tables: [...], columns: [...] },
   â”‚     connection_string: "mysql://...",
   â”‚     use_agent: true/false
   â”‚   }
   â”‚
   â”œâ”€â–º Route handler: app/api/analytics/route.ts
   â”‚
   â”œâ”€â–º Decision: Agent-based or direct LLM?
   â”‚   â”‚
   â”‚   â”œâ”€â–º If use_agent=true or large database:
   â”‚   â”‚   â””â”€â–º generateDashboardMetricsWithAgent()
   â”‚   â”‚       â”œâ”€â–º Identifies key tables (scoring algorithm)
   â”‚   â”‚       â”‚   â””â”€â–º Scores tables based on:
   â”‚   â”‚       â”‚       â”œâ”€â–º Numeric columns (for aggregations)
   â”‚   â”‚       â”‚       â”œâ”€â–º Date columns (for time series)
   â”‚   â”‚       â”‚       â””â”€â–º Category columns (for distributions)
   â”‚   â”‚       â”œâ”€â–º Reduces metadata to top 10 tables
   â”‚   â”‚       â””â”€â–º Calls generateDashboardMetrics()
   â”‚   â”‚
   â”‚   â””â”€â–º generateDashboardMetrics()
   â”‚       â”œâ”€â–º llm-service.ts
   â”‚       â”‚   â”œâ”€â–º Builds prompt requesting 6-8 metrics
   â”‚       â”‚   â”œâ”€â–º Includes metadata (reduced if agent-based)
   â”‚       â”‚   â”œâ”€â–º Calls OpenAI API
   â”‚       â”‚   â””â”€â–º Returns: { dashboard_metrics: [...] }
   â”‚       â”‚
   â”‚       â””â”€â–º Each metric contains:
   â”‚           â”œâ”€â–º metric_name: "Total Revenue"
   â”‚           â”œâ”€â–º query_content: "SELECT SUM(amount)..."
   â”‚           â”œâ”€â–º visualization_type: "auto"
   â”‚           â””â”€â–º insight_summary: "Shows total revenue..."
   â”‚
   â”œâ”€â–º Post-processing
   â”‚   â””â”€â–º query-post-processor.ts
   â”‚       â””â”€â–º Ensures queries return data
   â”‚
   â”œâ”€â–º Frontend receives metrics
   â”‚
   â”œâ”€â–º For each metric:
   â”‚   â”œâ”€â–º Execute query (POST /api/analytics/execute)
   â”‚   â”œâ”€â–º Check if returns data
   â”‚   â”œâ”€â–º Auto-select visualization type
   â”‚   â””â”€â–º Render chart
   â”‚
   â””â”€â–º Display grid of metrics with visualizations
```

### Flow 5: CSV File Upload & Query

```
1. User uploads CSV file
   â”‚
   â”œâ”€â–º FileUpload.tsx component
   â”‚   â””â”€â–º User selects file
   â”‚
   â”œâ”€â–º POST /api/analytics/upload
   â”‚   â”œâ”€â–º Saves file to uploads/ directory
   â”‚   â”œâ”€â–º Parses CSV headers
   â”‚   â”œâ”€â–º Detects data types
   â”‚   â”œâ”€â–º Creates DataSource record in Prisma
   â”‚   â””â”€â–º Returns: { dataSourceId, metadata }
   â”‚
   â”œâ”€â–º Frontend stores metadata
   â”‚
   â”œâ”€â–º User asks question
   â”‚   â””â”€â–º Same flow as Ad-Hoc Query (Flow 3)
   â”‚
   â””â”€â–º Query execution
       â””â”€â–º csv-query-executor.ts
           â”œâ”€â–º Reads CSV file
           â”œâ”€â–º Parses into array of objects
           â”œâ”€â–º Executes query logic (filtering, grouping, etc.)
           â””â”€â–º Returns results
```

### Flow 6: LangSmith Tracing (Observability)

```
Every LLM call is automatically traced:
â”‚
â”œâ”€â–º langsmith-tracer.ts
â”‚   â”œâ”€â–º Checks: LANGCHAIN_TRACING_V2=true
â”‚   â”œâ”€â–º Wraps OpenAI client with LangSmith
â”‚   â””â”€â–º All calls automatically traced
â”‚
â”œâ”€â–º LangSmith captures:
â”‚   â”œâ”€â–º Input: Full prompt/messages
â”‚   â”œâ”€â–º Output: LLM response
â”‚   â”œâ”€â–º Tokens: Input/output token count
â”‚   â”œâ”€â–º Latency: Execution time
â”‚   â”œâ”€â–º Metadata: Model, temperature, etc.
â”‚   â””â”€â–º Errors: Failed calls with context
â”‚
â””â”€â–º View in LangSmith dashboard
    â””â”€â–º https://smith.langchain.com
        â””â”€â–º Projects â†’ analytics-engine
```

---

## ğŸ”§ Key Components

### Frontend Components

#### `SchoolLogin.tsx`
- **Purpose**: Authentication UI
- **Features**: Email/password login, session management
- **Flow**: Validates â†’ Calls `/api/auth/login` â†’ Stores session â†’ Redirects

#### `FileUpload.tsx`
- **Purpose**: CSV file upload interface
- **Features**: Drag & drop, file validation, progress tracking
- **Flow**: Upload â†’ Parse â†’ Save â†’ Create DataSource

#### `AdhocQuery.tsx`
- **Purpose**: Natural language query interface
- **Features**: Question input, query display, visualization, data modal
- **Flow**: Question â†’ Generate query â†’ Execute â†’ Visualize

#### `DashboardMetrics.tsx`
- **Purpose**: Auto-generated dashboard display
- **Features**: Grid layout, metric cards, individual visualizations
- **Flow**: Load â†’ Generate metrics â†’ Execute queries â†’ Display charts

#### `AIAnalyticsSuggestions.tsx`
- **Purpose**: AI-powered question suggestions
- **Features**: Generates relevant questions based on schema
- **Flow**: Analyze schema â†’ Generate suggestions â†’ Display â†’ User clicks

#### `VisualizationRenderer.tsx`
- **Purpose**: Chart rendering wrapper
- **Features**: Routes to appropriate chart component
- **Components**: BarChart, LineChart, PieChart, ScatterPlot, Gauge, Table

### Backend Services

#### `llm-service.ts`
- **Purpose**: Core LLM query generation
- **Functions**:
  - `generateAdhocQuery()` - Direct LLM query generation
  - `generateDashboardMetrics()` - Dashboard metrics generation
  - `generateAdhocQueryWithLangGraphAgent()` - Agent-based generation
  - `reduceMetadataForAdhocQuery()` - Metadata reduction for large DBs

#### `query-executor.ts`
- **Purpose**: SQL query execution and error handling
- **Functions**:
  - `executeSQLQuery()` - Execute query with error handling
  - `fixGroupByWithLLM()` - Auto-fix GROUP BY violations
  - `fixColumnErrorWithLLM()` - Auto-fix column name errors

#### `schema-introspection.ts`
- **Purpose**: Database schema detection
- **Functions**:
  - `introspectSQLSchema()` - Get schema from SQL database
  - `introspectCSVSchema()` - Get schema from CSV file

#### `visualization-selector.ts`
- **Purpose**: Automatic chart type selection
- **Function**: `autoSelectVisualizationType()` - Analyzes data and query to select best chart

#### `agent-service.ts`
- **Purpose**: LangChain agent integration
- **Functions**:
  - `generateQueryWithSQLAgent()` - LangChain SQL agent
  - `exploreRelevantSchema()` - Schema exploration tool

#### `langsmith-tracer.ts`
- **Purpose**: LangSmith observability
- **Functions**:
  - `createTracedOpenAI()` - Wraps OpenAI client with tracing
  - `traceFunction()` - Trace custom functions
  - `getLangSmithStatus()` - Get tracing status

### Python Backend

#### `api_server.py`
- **Purpose**: Flask REST API server
- **Endpoints**:
  - `POST /introspect` - Schema introspection
  - `POST /execute` - SQL query execution
  - `POST /agent/query` - LangChain agent query
  - `POST /agent/explore-schema` - Schema exploration

#### `schema_introspection.py`
- **Purpose**: SQLAlchemy-based schema detection
- **Function**: `introspect_sql_schema()` - Inspects database structure

#### `agent_service.py`
- **Purpose**: LangChain SQL agent service
- **Function**: `generate_query()` - Uses LangChain SQL agent

---

## ğŸŒ API Endpoints

### Authentication
- `POST /api/auth/login` - School login

### Analytics
- `POST /api/analytics` - Generate queries/metrics
  - Mode: `ADHOC_QUERY` or `DASHBOARD_METRICS`
- `POST /api/analytics/execute` - Execute SQL query
- `POST /api/analytics/upload` - Upload CSV file
- `GET /api/analytics/schema` - Get schema
- `GET /api/analytics/data-sources/[id]/schema` - Get data source schema
- `POST /api/analytics/suggestions` - Get AI suggestions
- `GET /api/analytics/history` - Get query history
- `POST /api/analytics/history` - Save query to history

### Python Backend (Flask)
- `GET /health` - Health check
- `POST /introspect` - Schema introspection
- `POST /execute` - Execute SQL query
- `POST /agent/query` - LangChain agent query
- `POST /agent/explore-schema` - Schema exploration

---

## ğŸ“ File Structure

```
k_gai/
â”œâ”€â”€ app/                          # Next.js app directory
â”‚   â”œâ”€â”€ page.tsx                  # Home page (login)
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â””â”€â”€ page.tsx              # Analytics dashboard
â”‚   â””â”€â”€ api/                      # API routes
â”‚       â”œâ”€â”€ auth/login/route.ts   # Login endpoint
â”‚       â””â”€â”€ analytics/
â”‚           â”œâ”€â”€ route.ts           # Main analytics endpoint
â”‚           â”œâ”€â”€ execute/route.ts   # Query execution
â”‚           â”œâ”€â”€ upload/route.ts    # File upload
â”‚           â””â”€â”€ suggestions/route.ts
â”‚
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ SchoolLogin.tsx
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ AdhocQuery.tsx
â”‚       â”œâ”€â”€ DashboardMetrics.tsx
â”‚       â”œâ”€â”€ FileUpload.tsx
â”‚       â”œâ”€â”€ AIAnalyticsSuggestions.tsx
â”‚       â”œâ”€â”€ QueryHistory.tsx
â”‚       â”œâ”€â”€ VisualizationRenderer.tsx
â”‚       â””â”€â”€ visualizations/
â”‚           â”œâ”€â”€ BarChart.tsx
â”‚           â”œâ”€â”€ LineChart.tsx
â”‚           â”œâ”€â”€ PieChart.tsx
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ analytics-engine/              # Core analytics engine
â”‚   â”œâ”€â”€ services/                 # Business logic
â”‚   â”‚   â”œâ”€â”€ llm-service.ts        # LLM query generation
â”‚   â”‚   â”œâ”€â”€ query-executor.ts     # Query execution
â”‚   â”‚   â”œâ”€â”€ schema-introspection.ts
â”‚   â”‚   â”œâ”€â”€ visualization-selector.ts
â”‚   â”‚   â”œâ”€â”€ agent-service.ts
â”‚   â”‚   â””â”€â”€ langsmith-tracer.ts
â”‚   â”œâ”€â”€ agents/                   # Agent implementations
â”‚   â”‚   â”œâ”€â”€ query-agent.ts        # LangGraph agent
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ query-validator.ts
â”‚   â”‚       â””â”€â”€ schema-explorer.ts
â”‚   â”œâ”€â”€ python-backend/           # Python Flask server
â”‚   â”‚   â”œâ”€â”€ api_server.py
â”‚   â”‚   â”œâ”€â”€ schema_introspection.py
â”‚   â”‚   â”œâ”€â”€ query_executor.py
â”‚   â”‚   â””â”€â”€ agent_service.py
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts              # TypeScript types
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ date-utils.ts
â”‚       â””â”€â”€ langsmith-tracer.ts
â”‚
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ prisma.ts                 # Prisma client
â”‚
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma             # Database schema
â”‚   â””â”€â”€ seed.ts                   # Seed data
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ create_realestate_tenant.ts
â”‚   â””â”€â”€ test_realestate_tenant.ts
â”‚
â”œâ”€â”€ uploads/                      # Uploaded CSV files
â”‚
â”œâ”€â”€ package.json                  # Dependencies
â”œâ”€â”€ tsconfig.json                 # TypeScript config
â”œâ”€â”€ tailwind.config.js           # Tailwind config
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Setup & Installation

### Prerequisites
- Node.js 18+
- Python 3.8+
- MySQL/PostgreSQL (for SQL databases)
- OpenAI API key

### Installation Steps

1. **Install Node.js dependencies**
```bash
npm install
```

2. **Install Python dependencies**
```bash
cd analytics-engine/python-backend
pip install -r requirements.txt
```

3. **Setup Prisma database**
```bash
npx prisma generate
npx prisma migrate dev
npm run prisma:seed
```

4. **Configure environment variables**
Create `.env.local`:
```env
# OpenAI
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4-turbo-preview

# Database (for SQL sources)
DATABASE_URL=mysql://user:password@localhost:3306/dbname

# LangSmith (optional)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=analytics-engine
```

5. **Start Python backend** (in separate terminal)
```bash
npm run python:backend
# Or: cd analytics-engine/python-backend && python api_server.py
```

6. **Start Next.js dev server**
```bash
npm run dev
```

7. **Access application**
- Frontend: http://localhost:3000
- Python API: http://localhost:8000

### Default Login Credentials
- Email: `schoola@gmail.com`
- Password: `neha`

---

## ğŸ“Š Data Flow Summary

1. **User Login** â†’ Authenticate â†’ Create DataSource â†’ Store metadata
2. **Schema Detection** â†’ Introspect database/CSV â†’ Save schema â†’ Display UI
3. **Query Generation** â†’ User question â†’ LLM/Agent â†’ SQL query â†’ Execute â†’ Visualize
4. **Dashboard Metrics** â†’ Generate 6-8 metrics â†’ Execute queries â†’ Display charts
5. **Observability** â†’ All LLM calls traced â†’ View in LangSmith dashboard

---

## ğŸ” Key Technologies Explained

### Next.js 14
- **App Router**: File-based routing with `app/` directory
- **Server Components**: Server-side rendering by default
- **API Routes**: Backend endpoints in `app/api/`

### Prisma
- **ORM**: Type-safe database access
- **Schema**: Defined in `prisma/schema.prisma`
- **Client**: Generated TypeScript client

### LangChain/LangGraph
- **Agents**: Multi-step reasoning workflows
- **Tools**: Reusable functions (schema exploration, validation)
- **SQL Agent**: Specialized agent for SQL generation

### LangSmith
- **Tracing**: Automatic LLM call tracking
- **Observability**: Token usage, latency, costs
- **Debugging**: Full request/response logging

### Recharts
- **Chart Library**: React chart components
- **Types**: Bar, Line, Pie, Scatter, etc.
- **Styling**: PowerBI-inspired design

---

## ğŸ¯ Summary

This application is a **complete AI-powered analytics platform** that:

1. **Authenticates** users (multi-tenant)
2. **Detects** database/CSV schemas automatically
3. **Generates** SQL queries from natural language using AI
4. **Executes** queries with automatic error fixing
5. **Visualizes** results with beautiful charts
6. **Tracks** everything with LangSmith observability

The system uses **Next.js** for the frontend, **TypeScript** for type safety, **OpenAI GPT-4** for AI, **LangChain** for agents, **Prisma** for database access, and **Python Flask** for schema introspection.

---

## ğŸ“š Additional Documentation

- `LANGSMITH_SETUP.md` - LangSmith integration guide
- `REALESTATE_TENANT_SETUP.md` - Multi-tenant setup guide
- `prisma/schema.prisma` - Database schema definition

---

**Built with â¤ï¸ using Next.js, TypeScript, OpenAI, LangChain, and Python**

